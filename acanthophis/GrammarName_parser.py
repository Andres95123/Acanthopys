# ==============================================================================
#  THIS FILE HAS BEEN AUTOMATICALLY GENERATED BY ACANTHOPYS
#  A Parsing Expression Grammar (PEG) Compiler-Compiler
# ==============================================================================
#
#  Generator: Acanthopys 0.1.0
#  Generated at: 2025-12-18 13:55:08
#
#  WARNING: DO NOT EDIT THIS FILE MANUALLY.
#  ANY CHANGES WILL BE OVERWRITTEN UPON REGENERATION.
#
# ==============================================================================

import re
from dataclasses import dataclass


@dataclass(frozen=True)
class Token:
    type: str
    value: str
    line: int = 0
    column: int = 0
    
    def __float__(self):
        return float(self.value)
        
    def __int__(self):
        return int(self.value)
        
    def __str__(self):
        return self.value

    def __repr__(self):
        return f"{self.value!r}"

class ParseError(Exception):
    pass

class AddNode:
    def __init__(self, *args, **kwargs):
        self.args = args
        for k, v in kwargs.items():
            setattr(self, k, v)
    def __repr__(self):
        params = []
        if self.args:
            params.extend([repr(a) for a in self.args])
        for k, v in self.__dict__.items():
            if k != 'args':
                params.append(repr(v))
        return f'AddNode({', '.join(params)})'

class NumberNode:
    def __init__(self, *args, **kwargs):
        self.args = args
        for k, v in kwargs.items():
            setattr(self, k, v)
    def __repr__(self):
        params = []
        if self.args:
            params.extend([repr(a) for a in self.args])
        for k, v in self.__dict__.items():
            if k != 'args':
                params.append(repr(v))
        return f'NumberNode({', '.join(params)})'

class Lexer:
    def __init__(self, text):
        self.text = text
        self.pos = 0
        self.tokens = []
        self.tokenize()

    def tokenize(self):
        # Regex patterns
        token_specs = [
            ('TOKEN_NUMBER', r'\d+'),
            ('TOKEN_PLUS', r'\+'),
            ('TOKEN_WS', r'\s+'),
            ('MISMATCH', r'.'),
        ]

        group_map = {'TOKEN_NUMBER': 'NUMBER', 'TOKEN_PLUS': 'PLUS', 'TOKEN_WS': 'WS'}

        # Compile regex
        tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specs)
        get_token = re.compile(tok_regex).match

        skipped_tokens = {'WS'}
        line_num = 1
        line_start = 0
        mo = get_token(self.text)
        while mo is not None:
            kind = mo.lastgroup
            value = mo.group(kind)
            if kind == 'MISMATCH':
                raise ParseError(f'Unexpected character {value!r} on line {line_num}')
            
            # Map back to token type
            token_type = group_map.get(kind, kind)
            
            if token_type in skipped_tokens:
                pass
            else:
                self.tokens.append(Token(token_type, value, line_num, mo.start() - line_start))
            
            # Update position
            pos = mo.end()
            mo = get_token(self.text, pos)
            if pos == len(self.text): break

class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0
        self.memo = {}

    def current(self):
        if self.pos < len(self.tokens):
            return self.tokens[self.pos]
        return None

    def consume(self, type_name=None):
        token = self.current()
        if token and (type_name is None or token.type == type_name):
            self.pos += 1
            return token
        return None

    def expect(self, type_name):
        token = self.consume(type_name)
        if not token:
            raise ParseError(f'Expected {type_name} at {self.pos}')
        return token

    def parse_StartRule(self):
        # Memoization check
        key = ('StartRule', self.pos)
        if key in self.memo:
            res, end_pos = self.memo[key]
            if isinstance(res, Exception):
                raise res
            self.pos = end_pos
            return res

        start_pos = self.pos
        # Option 0
        self.pos = start_pos
        try:
            left = self.parse_Term()
            _ = self.expect('PLUS')
            right = self.parse_StartRule()
            res = AddNode(left, right)
            self.memo[key] = (res, self.pos)
            return res
        except ParseError:
            pass
        # Option 1
        self.pos = start_pos
        try:
            child = self.parse_Term()
            res = child
            self.memo[key] = (res, self.pos)
            return res
        except ParseError:
            pass
        error = ParseError('No alternative matched for StartRule')
        self.memo[key] = (error, start_pos)
        raise error

    def parse_Term(self):
        # Memoization check
        key = ('Term', self.pos)
        if key in self.memo:
            res, end_pos = self.memo[key]
            if isinstance(res, Exception):
                raise res
            self.pos = end_pos
            return res

        start_pos = self.pos
        # Option 0
        self.pos = start_pos
        try:
            value = self.expect('NUMBER')
            res = NumberNode(float(value))
            self.memo[key] = (res, self.pos)
            return res
        except ParseError:
            pass
        error = ParseError('No alternative matched for Term')
        self.memo[key] = (error, start_pos)
        raise error
